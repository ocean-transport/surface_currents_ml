{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Geostrophic Balance\n",
    "\n",
    "By Ryan Abernathey.\n",
    "\n",
    "Adapted from Ph.D. work by Anirban Sinha.\n",
    "\n",
    "Sinha, Anirban. _Temporal Variability in Ocean Mesoscale and Submesoscale Turbulence_. Columbia University, 2019. https://doi.org/10.7916/d8-bngk-r215\n",
    "\n",
    "## Geostrophic Balance\n",
    "Geostrophic balance describes the relationship between pressure gradients and winds / currents. At the ocean surface, it is expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "u &= - \\frac{g}{f} \\frac{\\partial \\eta}{\\partial y} \\\\\n",
    "v &= \\frac{g}{f} \\frac{\\partial \\eta}{\\partial x}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the sea surface height relative to the geoid, $g$ is gravitational acceleration, and $f = 2 \\Omega \\sin(\\lambda)$ is the [Coriolis frequency](https://en.wikipedia.org/wiki/Coriolis_frequency). The coordinates $x$ and $y$ are local cartesian coordinates for the zonal and meridional directions, and $u$ and $v$ are the corresponding velocity components.\n",
    "\n",
    "To calculate geostrophic balance from gridded data, we usually use some kind of finite difference scheme. The details of how this is implemented depend on the nature of the dataset--observations vs. model, C-grid, B-grid, etc.--but the general idea is that we will use some sort of n-point _stencil_ in the neighborhood around the point of interest. Larger $n$ corresponds with higherer order numerical schemes. The simplest centered-difference scheme involves a 3x3 stencil.\n",
    "\n",
    "So we can think of geostrophic balance as model which takes as its inputs:\n",
    "- sea surface height $\\eta$\n",
    "- position (needed for derivatives and Coriolis parameter)\n",
    "On a 3x3 stencil and returns $u$ and $v$.\n",
    "\n",
    "The problem is nonlinear on the sphere because $f$, $dx$, and $dy$ all vary in space.\n",
    "\n",
    "**Can we teach a neural network to do this?**\n",
    "\n",
    "![local stencil](local_stencil_machine_learning.svg)\n",
    "\n",
    "We hypothesize that this is a good test problem for more ambitious machine learning related to subgrid parameterization.\n",
    "So what is the most efficient architecture for this sort of problem?\n",
    "\n",
    "In this notebook, we use two different approaches.\n",
    "\n",
    "1. Generate the stencil manually as a post-processing step, and then use a fully-connected neural network on each point individually. **Works!**\n",
    "1. Use a 2D CNN to create the stencil, followed by 1x1 convolution layers. **Doesn't work!**\n",
    "\n",
    "The big question I have for anyone reading this is _why doesn't approach 2 work?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import gcsfs\n",
    "from glob import glob\n",
    "from dask.diagnostics import ProgressBar, Profiler\n",
    "import dask\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "import datashader\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [xbatcher](https://xbatcher.readthedocs.io/en/latest/), a new library we are developing to help with xarray -> deep learning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbatcher import BatchGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CESM Ocean GCM Dataset\n",
    "\n",
    "We will use data from a high-resolution CESM POP ocean model simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "cat_url = 'https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml'\n",
    "cat = intake.Catalog(cat_url)\n",
    "ds = cat.ocean.CESM_POP.CESM_POP_hires_control.to_dask()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.rename({'U1_1':'U', 'V1_1':'V', 'TAUX_2':'TAUX', 'TAUY_2':'TAUY', 'SSH_2':'SSH', 'ULONG':'XU', 'ULAT':'YU'})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 3D Euclidean Coordiantes\n",
    "\n",
    "We have found it is best to use 3D Euclidean coordiantes, rather than lat / lon, for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_3d_coords(lon,lat):\n",
    "    X = np.sin(np.radians(lat))\n",
    "    Y = np.sin(np.radians(lon))*np.cos(np.radians(lat))\n",
    "    Z = -np.cos(np.radians(lon))*np.cos(np.radians(lat))\n",
    "    return (X,Y,Z)\n",
    "\n",
    "X, Y, Z = make_3d_coords(ds.XU.data, ds.YU.data)\n",
    "ds['X'] = ds.XU.dims, X\n",
    "ds['Y'] = ds.XU.dims, Y\n",
    "ds['Z'] = ds.XU.dims, Z\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Create Stencil in Pre-Processing\n",
    "\n",
    "Here we use xarray's `shift` function to create the stencil.\n",
    "This works for 3x3 but scales very poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_variables(ds, shift_vars, corner_points=True):\n",
    "    \"\"\"Augment xarray dataset with shifted versions of all variables in\n",
    "    `shift_vars` list.\"\"\"\n",
    "    \n",
    "    # needed to deal with different xbatcher possibilities \n",
    "    if 'nlon_input' in ds.dims:\n",
    "        xdim = 'nlon_input'\n",
    "    else:\n",
    "        xdim = 'nlon'\n",
    "    if 'nlat_input' in ds.dims:\n",
    "        ydim = 'nlat_input'\n",
    "    else:\n",
    "        ydim = 'nlat'  \n",
    "        \n",
    "    ds = ds.copy()\n",
    "    shift_vars = ['SSH', 'X', 'Y', 'Z']\n",
    "\n",
    "    shifts = {'_e': {xdim: -1},\n",
    "              '_w': {xdim: 1},\n",
    "             '_n': {ydim: -1},\n",
    "             '_s': {ydim: 1}}\n",
    "    if corner_points:\n",
    "        shifts.update({\n",
    "             '_ne': {xdim: -1, ydim: -1},\n",
    "             '_nw': {xdim: 1, ydim: -1},\n",
    "             '_se': {xdim: -1, ydim: 1},\n",
    "             '_sw': {xdim: 1, ydim: 1}})\n",
    "\n",
    "    for var in shift_vars:\n",
    "        for suf, shift in shifts.items():\n",
    "            ds[var + suf] = ds[var].shift(**shift)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xbatcher creates generators which help us iterate through our xarray dataset.\n",
    "Here are some functions that do the need postprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols=['U','V']\n",
    "feature_cols = ['X', 'Y', 'Z',\n",
    "                'X_e','X_w','X_n','X_s',\n",
    "                'Y_e','Y_w','Y_n','Y_s',\n",
    "                'Z_e','Z_w','Z_n','Z_s',\n",
    "                'SSH',\n",
    "                'SSH_e','SSH_w','SSH_n','SSH_s']\n",
    "coord_cols = ['XU', 'YU']\n",
    "\n",
    "def transform_batch(batch_ds, return_coords=False):\n",
    "    \"\"\"Postprocessing to transform each batch from xbatcher into suitable input for keras.\"\"\"\n",
    "    \n",
    "    batch_w_shift = shift_variables(batch_ds, ['X', 'Y', 'Z', 'SSH'], corner_points=False)\n",
    "    \n",
    "    # convert to pandas dataframe, ~15 s\n",
    "    # the slow part is the dataframe conversion, where you have to call\n",
    "    # \"stack\". There is no real way around this. I tried implementing\n",
    "    # it in numpy, which was a bit faster, but then we can't call\n",
    "    # .dropna in the next step\n",
    "    if 'sample' in batch_w_shift:\n",
    "        batch_w_shift = batch_w_shift.drop('sample')\n",
    "    df = batch_w_shift.to_dataframe().reset_index(drop=True)\n",
    "    \n",
    "    # ~2 s\n",
    "    df_dropped = df.dropna()\n",
    "\n",
    "    X = df_dropped.loc[:, feature_cols].values\n",
    "    y = df_dropped.loc[:, target_cols].values\n",
    "    \n",
    "    if return_coords:\n",
    "        coords = df_dropped.loc[:, coord_cols].values\n",
    "        return X, y, coords\n",
    "    else:\n",
    "        return X, y\n",
    "\n",
    "\n",
    "default_variables = ['X', 'Y', 'Z', 'U', 'V', 'TAUX', 'TAUY','SST','SSH']\n",
    "coord_variables = ['XU', 'YU']\n",
    "\n",
    "def data_generator(ds, time_indexes=[], sub_batch_size=100, return_coords=False):\n",
    "    \"\"\"A generator we can pass to keras's `fit_generator` function.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : ndarray\n",
    "        The input features\n",
    "    y : ndarray\n",
    "        The targets\n",
    "    \"\"\"\n",
    "\n",
    "    if return_coords:\n",
    "        variables = default_variables + coord_variables\n",
    "    else:\n",
    "        variables = default_variables\n",
    "    \n",
    "    bg = BatchGenerator(ds.isel(time=time_indexes).reset_coords()[variables],\n",
    "                        batch_dims={'time': 1},\n",
    "                        input_dims={'nlon': 100, 'nlat': 100},\n",
    "                        input_overlap={'nlon' : 1, 'nlat' : 1},\n",
    "                        concat_input_dims=True, preload_batch=True)\n",
    "    \n",
    "    with dask.config.set(scheduler='single-threaded'):\n",
    "        for batch in bg:\n",
    "            print('\\n*** Loaded new Batch ***\\n')\n",
    "\n",
    "            bt = transform_batch(batch, return_coords=return_coords)    \n",
    "            X, y = bt[0], bt[1]\n",
    "\n",
    "            # randomize full batch\n",
    "            sample_idx = np.arange(X.shape[0])\n",
    "            np.random.shuffle(sample_idx)\n",
    "            X, y = X[sample_idx], y[sample_idx]\n",
    "        \n",
    "            if return_coords:\n",
    "                coords = (bt[2][sample_idx],)\n",
    "            else:\n",
    "                coords = ()\n",
    "\n",
    "            print(f'X.shape, y.shape: {X.shape}, {y.shape}')\n",
    "\n",
    "            if sub_batch_size:\n",
    "                n_samples = X.shape[0]\n",
    "                n_start = np.arange(0, n_samples, sub_batch_size)                \n",
    "                for i in n_start:\n",
    "                    imax = min(i + sub_batch_size, n_samples)\n",
    "                    yield (X[i:imax], y[i:imax]) + coords\n",
    "            else:\n",
    "                yield (X, y) + coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ds0 = ds.isel(time=11).reset_coords()[default_variables + ['XU', 'YU']].load()\n",
    "%time X, y, coords = transform_batch(ds0, return_coords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kinetic energy\n",
    "ke = 0.5*(y**2).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lonlat = np.hstack([coords, ke[:, None]])\n",
    "points_lonlat = hv.Points(data_lonlat, kdims=['lon', 'lat'], vdims=['z'], label=\"points\")\n",
    "agg = datashader.mean('z')\n",
    "datashade(points_lonlat, x_sampling=0.12, y_sampling=0.12,\n",
    "          aggregator=agg,\n",
    "          cmap=plt.cm.magma,\n",
    "          ).opts(width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use day indexes to separate test and training data\n",
    "\n",
    "training_selector = [30, 40]\n",
    "testing_selector = [50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = data_generator(ds, training_selector)\n",
    "%time X, y = next(iter(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes about 30 seconds.\n",
    "It's the slowest and most sketchy part of our workflow.\n",
    "However, a lot of data has been pre-loaded, and the next iteration will be much faster.\n",
    "Occasionally our generator will have to download and transform the next batch of data from xarray / zarr, leading to another 30s slowdown.\n",
    "\n",
    "_I wish there were a way to pre-load the next download/transform batch simultaneously while the model is training._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X, y = next(iter(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `X` is the input array (`numpy.ndarray`) of shape `(nsamples, nfeatures)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y` is the target, the 2D velocity vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are we can see from the output above that there are 5137262 samples in the full-length transformed batch.\n",
    "(We will need to pass this information to Keras soon.)\n",
    "Thats _5 million_ samples for _a single day of model output_.\n",
    "And there are 14965 days saved!\n",
    "There is clearly LOTS of data here.\n",
    "\n",
    "The [standard definition](https://keras.io/getting-started/faq/#what-does-sample-batch-epoch-mean) of `epoch` in Keras is\n",
    "> **Epoch**: an arbitrary cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation.\n",
    "\n",
    "So usually Epoch means all the data.\n",
    "But we are going to break with convention and **define an Epoch to be one day**.\n",
    "\n",
    "### Define Neural Network\n",
    "\n",
    "A very simple three-layer [Keras](https://keras.io/getting-started/sequential-model-guide/) fully connected neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nfeatures = X.shape\n",
    "noutput = y.shape[1]\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(nfeatures, input_shape=(len(feature_cols),),\n",
    "                       name='hidden_layer_1',))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(20, name='hidden_layer_2'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(10, name='hidden_layer_3'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(noutput, name='output_layer',))\n",
    "    \n",
    "# Define your optimizer \n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "# show a summary of the data\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how well the model does out of the box, with it's randomly generated weights, we can call `evaluate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number is the loss, the second is mean absolute error, the third the mean squared error.\n",
    "\n",
    "### Start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will help save training history more frequently\n",
    "# https://keras.io/callbacks/#create-a-callback\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, frequency=100):\n",
    "        self.frequency = frequency\n",
    "        self.batch_counter = 0\n",
    "        self.losses = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if batch % self.frequency == 0:\n",
    "            self.batch_counter += self.frequency\n",
    "            self.losses.append([logs.get('loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = data_generator(ds, training_selector)\n",
    "history = LossHistory()\n",
    "steps_per_epoch = 5137262 // 100 # I wish there were a way to pre-know this\n",
    "model.fit_generator(generator=gen, steps_per_epoch=steps_per_epoch, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.array(history.losses).squeeze()\n",
    "ds_hist = xr.Dataset({'loss': ('batch', loss)})\n",
    "ds_hist.loss.plot()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the model was able to learn something here.\n",
    "\n",
    "### Manually evaluate against test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds.isel(time=testing_selector[0]).reset_coords()[default_variables + ['XU', 'YU']].load()\n",
    "%time X_test, y_test, coords = transform_batch(ds_test, return_coords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that we understand how MAE is calculated\n",
    "y_err = y_pred - y_test\n",
    "(abs(y_err)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdims = ['true (cm/s)', 'predicted (cm/s)']\n",
    "\n",
    "u_data = np.array([y_test[:, 0], y_pred[:, 0]]).transpose()\n",
    "u_points = hv.Points(u_data, kdims=kdims, label=\"U\")\n",
    "\n",
    "v_data = np.array([y_test[:, 1], y_pred[:, 1]]).transpose()\n",
    "v_points = hv.Points(v_data, kdims=kdims, label=\"V\")\n",
    "\n",
    "line_1x1 = hv.Path(np.array([[-200, -200], [200, 200]]), kdims=kdims).opts(color='red', line_width=2)\n",
    "\n",
    "agg = datashader.mean('rms_vel')\n",
    "(datashade(u_points, cmap=plt.cm.binary) * line_1x1 +\n",
    " datashade(v_points, cmap=plt.cm.binary) * line_1x1 \n",
    ").opts(opts.RGB(width=500, height=500, show_grid=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_vel = np.sqrt((y_test**2).sum(axis=1))\n",
    "rms_vel_pred = np.sqrt((y_pred**2).sum(axis=1))\n",
    "rms_err = np.sqrt((y_err**2).sum(axis=1))\n",
    "\n",
    "data_lonlat = np.hstack([coords, rms_vel[:, None], rms_vel_pred[:, None], rms_err[:, None]])\n",
    "points_lonlat = hv.Points(data_lonlat, kdims=['lon', 'lat'],\n",
    "                          vdims=['rms_vel', 'rms_vel_pred', 'rms_error'], label=\"RMS Velocity\")\n",
    "\n",
    "plt_opts = dict(width=600, height=350, colorbar=True, tools=['hover'])\n",
    "\n",
    "(rasterize(points_lonlat, x_sampling=0.12, y_sampling=0.12,\n",
    "          aggregator=datashader.mean('rms_vel')\n",
    "          ).redim.range(rms_vel=(0, 150)).opts(cmap=plt.cm.Blues, **plt_opts)\n",
    " +\n",
    " rasterize(points_lonlat, x_sampling=0.12, y_sampling=0.12,\n",
    "          aggregator=datashader.mean('rms_vel_pred')\n",
    "          ).redim.range(rms_vel_pred=(0, 150)).opts(cmap=plt.cm.Blues, title='RMS Velocity Predicted', **plt_opts)\n",
    " +\n",
    " rasterize(points_lonlat, x_sampling=0.12, y_sampling=0.12,\n",
    "          aggregator=datashader.mean('rms_error')\n",
    "          ).opts(cmap=plt.cm.Reds, title='RMS Error', **plt_opts)\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: CNN\n",
    "\n",
    "The model is not bad. But it is inefficient. It won't scale well if we want to do 7x7 stencils.\n",
    "\n",
    "Can we make a CNN do the exact same thing?\n",
    "\n",
    "Now we will try to pass keras image-like data, with the different variables as different channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vars = ['U','V']\n",
    "feature_vars= ['X', 'Y', 'Z','SSH'] # 'TAUX','TAUY','SST'\n",
    "coord_vars = ['XU', 'YU']\n",
    "all_vars = target_vars + feature_vars + coord_vars\n",
    "\n",
    "# for use as input to keras\n",
    "# sample is the batch dimension\n",
    "# variable is the \"channel\"\n",
    "# nlon_input, nlat_input are the 2D \"image\" dimensions\n",
    "dimension_order = ['sample', 'variable', 'nlat_input', 'nlon_input']\n",
    "\n",
    "# this varies how large is the patch the the NN sees\n",
    "square_size = 32\n",
    "\n",
    "# possibly use normalization\n",
    "#normfac = {'SSH': 100., 'U': 15., 'V': 15.}\n",
    "normfac = {}\n",
    "\n",
    "def cnn_data_generator(ds, time_indexes=[], return_coords=False, sub_batch_size=10,\n",
    "                       trim_targets=1, remove_means=[], normfac={}):\n",
    "\n",
    "    bg = BatchGenerator(ds.isel(time=time_indexes).reset_coords()[all_vars],\n",
    "                        batch_dims={'time': 1},\n",
    "                        input_dims={'nlon': square_size, 'nlat': square_size},\n",
    "                        input_overlap={'nlon': square_size//2, 'nlat': square_size//2},\n",
    "                        concat_input_dims=True, preload_batch=True)\n",
    "    \n",
    "    with dask.config.set(scheduler='single-threaded'):\n",
    "        for batch in bg:\n",
    "            print('\\n*** Loaded new Batch ***\\n')\n",
    "            \n",
    "            # CNN can't handle NaNs\n",
    "            batch = batch.dropna('sample', subset=['SSH'])\n",
    "            \n",
    "            for var in remove_means:\n",
    "                batch[var] -= batch[var].mean(dim=['nlon_input', 'nlat_input'])\n",
    "\n",
    "            # normalize inputs\n",
    "            for varname, factor in normfac.items():\n",
    "                if varname in batch:\n",
    "                    batch[varname] /= factor\n",
    "            \n",
    "            # randomize batch order\n",
    "            sample_index = np.arange(batch.dims['sample'])\n",
    "            np.random.shuffle(sample_index)\n",
    "            batch = batch.isel(sample=sample_index)\n",
    "\n",
    "            X_da = batch[feature_vars].to_array()\n",
    "            y_da = batch[target_vars].to_array()\n",
    "            # transpose so that time is the first axis\n",
    "            X = X_da.transpose(*dimension_order).values\n",
    "            y = y_da.transpose(*dimension_order).values\n",
    "            \n",
    "            # needed because CNN padding reduces size\n",
    "            if trim_targets:\n",
    "                y = y[..., trim_targets:-trim_targets, trim_targets:-trim_targets]\n",
    "            \n",
    "            if return_coords:\n",
    "                coords = (batch[coords_vars].to_array()\n",
    "                                            .transpose(*dimension_order)\n",
    "                                            .values,)\n",
    "            else:\n",
    "                coords = ()\n",
    "\n",
    "            print(f'X.shape, y.shape: {X.shape}, {y.shape}')\n",
    "\n",
    "            if sub_batch_size:\n",
    "                n_samples = X.shape[0]\n",
    "                n_start = np.arange(0, n_samples, sub_batch_size)\n",
    "                for i in n_start:\n",
    "                    imax = min(i + sub_batch_size, n_samples)\n",
    "                    yield (X[i:imax], y[i:imax]) + coords\n",
    "            else:\n",
    "                yield (X, y) + coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BatchGenerator(ds.isel(time=[6, 7]).reset_coords()[all_vars],\n",
    "                    batch_dims={'time': 1},\n",
    "                    input_dims={'nlon': square_size, 'nlat': square_size},\n",
    "                    input_overlap={'nlon': square_size//2, 'nlat': square_size//2},\n",
    "                    concat_input_dims=True, preload_batch=True)\n",
    "batch = next(iter(bg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop batches with missing data in them\n",
    "batch = batch.dropna('sample', subset=['SSH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize data within batch\n",
    "sample_index = np.arange(batch.dims['sample'])\n",
    "np.random.shuffle(sample_index)\n",
    "batch_rand = batch.isel(sample=sample_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_ds = hv.Dataset(batch_rand.drop('sample'))\n",
    "\n",
    "images = []\n",
    "for vname in ['SSH', 'U', 'V']:\n",
    "    im = hv_ds.to(hv.Image, kdims=['nlon_input', 'nlat_input'],\n",
    "                  vdims=[vname], dynamic=True, label=vname)\n",
    "    images.append(im.opts(cmap='viridis', colorbar=True, width=360, height=300))\n",
    "\n",
    "images[0] + images[1] + images[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do all that stuff via one generator\n",
    "\n",
    "gen_cnn = cnn_data_generator(ds, training_selector, sub_batch_size=1)\n",
    "%time X, y = next(iter(gen_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each iteration returns one sample, four channels, 32x32 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Add, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something I came up with that creates a layer of un-trainable convolution filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a convolution layer with fixed weights\n",
    "def fixed_conv2d(m, input_shape=None):\n",
    "\n",
    "    nfilters = 5\n",
    "    # the 2D filters\n",
    "    filters = [[[0, 0, 0], [0,  1, 0], [0, 0, 0]], # center\n",
    "               [[0, 0, 0], [1,  0, 0], [0, 0, 0]], # left\n",
    "               [[0, 0, 0], [0,  0, 1], [0, 0, 0]], # right\n",
    "               [[0, 1, 0], [0,  0, 0], [0, 0, 0]], # up \n",
    "               [[0, 0, 0], [0,  0, 0], [0, 1, 0]], # down\n",
    "              ]\n",
    "    # we want one of these for each channel\n",
    "    # assuming channels_first\n",
    "    nchannels = input_shape[0]\n",
    "    \n",
    "    # replicate the same filter weights for all channels\n",
    "    weights = np.tile(np.concatenate([np.array(f)[..., None, None]\n",
    "                                      for f in filters], axis=-1),\n",
    "                      (1, 1, nchannels, 1))\n",
    "    print(weights.shape)\n",
    "    # weights shape = (3, 3, nchannels, nfilters)\n",
    "    \n",
    "    layer = keras.layers.convolutional.DepthwiseConv2D(\n",
    "                    (3, 3), depth_multiplier=5,\n",
    "                    input_shape=input_shape, padding='valid',\n",
    "                    use_bias=False, trainable=False)\n",
    "    # output channels = nchannels * depth_multiplier\n",
    "    \n",
    "    m.add(layer)\n",
    "    layer.set_weights([weights])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_debug = keras.Sequential()\n",
    "input_conv_layer = fixed_conv2d(model_debug, input_shape=X.shape[1:])\n",
    "model_debug.compile(loss='mae', optimizer='sgd')\n",
    "model_debug.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertify that convolution-based shifting works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_debug = model_debug.predict(X)\n",
    "y_debug.shape\n",
    "y_debug_da = xr.DataArray(y_debug, dims=['sample', 'channel', 'nlat', 'nlon'])\n",
    "y_debug_da[0, :5].plot(col='channel', col_wrap=5)\n",
    "plt.figure()\n",
    "y_debug_da[0, 5:10].plot(col='channel', col_wrap=5)\n",
    "plt.figure()\n",
    "y_debug_da[0, 10:15].plot(col='channel', col_wrap=5)\n",
    "y_debug_da[0, 15:20].plot(col='channel', col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh = y_debug_da[0, 15:20]\n",
    "(ssh - ssh[0]).plot(col='channel', col_wrap=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate original model in CNN\n",
    "\n",
    "It has the _exact same number of trainable params_ as the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "nfeatures = X.shape[1]\n",
    "\n",
    "# this layer should do the same thing that our \"shifts\" parameter did:\n",
    "# create new features based on the neighbors.\n",
    "# its weights are not tuneable!\n",
    "# variable length input\n",
    "input_conv_layer = fixed_conv2d(model, input_shape=(nfeatures, None, None))\n",
    "\n",
    "# from here on it is a \"local\" dense network\n",
    "model.add(keras.layers.convolutional.Conv2D(20, 1))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.convolutional.Conv2D(20, 1))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.convolutional.Conv2D(10, 1))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.convolutional.Conv2D(2, 1))\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better way to do this: Time Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference from fully-connected example:** We need to remove the mean SSH from each image.\n",
    "Otherwise the model isn't able to learn.\n",
    "\n",
    "It would be great if we could avoid this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs = 1\n",
    "\n",
    "gen_cnn = cnn_data_generator(ds, training_selector, sub_batch_size=sbs, remove_means=['SSH'])\n",
    "history = LossHistory()\n",
    "steps_per_epoch = 17484/sbs # I wish there were a way to pre-know this\n",
    "model.fit_generator(generator=gen_cnn, steps_per_epoch=steps_per_epoch, epochs=2, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.array(history.losses).squeeze()\n",
    "ds_hist = xr.Dataset({'loss': ('batch', loss)})\n",
    "ds_hist.loss.plot()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am confused about these results. The loss function appears to be much more noisy. However, watching the mae diagnostics as the model trains, I don't see those same fluctuations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model to the full output\n",
    "\n",
    "Because of the way we set up the model (2400 x 3600), we can now run it on the full global image.\n",
    "However, because we aren't using 32 x 32 squares, we also don't apply the same normalization (removing the mean from ssh). This could contribute to the problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = ds[feature_vars].reset_coords(drop=True).isel(time=testing_selector[0]).to_array().values[None,...]\n",
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = ds[target_vars].reset_coords(drop=True).isel(time=testing_selector[0]).to_array().values[None,:,1:-1, 1:-1]\n",
    "y_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred = model.predict(X_full)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(abs(y_pred - y_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdims = ['true (cm/s)', 'predicted (cm/s)']\n",
    "\n",
    "u_data = np.array([y_full[0, 0].ravel(), y_pred[0, 0].ravel()]).transpose()\n",
    "u_points = hv.Points(u_data, kdims=kdims, label=\"U\")\n",
    "\n",
    "v_data = np.array([y_full[0, 1].ravel(), y_pred[0, 1].ravel()]).transpose()\n",
    "v_points = hv.Points(v_data, kdims=kdims, label=\"V\")\n",
    "\n",
    "line_1x1 = hv.Path(np.array([[-200, -200], [200, 200]]), kdims=kdims).opts(color='red', line_width=2)\n",
    "\n",
    "agg = datashader.mean('rms_vel')\n",
    "(datashade(u_points, cmap=plt.cm.binary) * line_1x1 +\n",
    " datashade(v_points, cmap=plt.cm.binary) * line_1x1 \n",
    ").opts(opts.RGB(width=500, height=500, show_grid=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.concatenate((ds.XU.values[1:-1, 1:-1].ravel()[:, None],\n",
    "                         ds.YU.values[1:-1, 1:-1].ravel()[:, None]), axis=1)\n",
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_err = y_pred - y_full\n",
    "rms_vel = np.sqrt((y_full**2).sum(axis=1)).ravel()\n",
    "rms_vel_pred = np.sqrt((y_pred**2).sum(axis=1)).ravel()\n",
    "rms_err = np.sqrt((y_err**2).sum(axis=1)).ravel()\n",
    "\n",
    "data_lonlat = np.hstack([coords, rms_vel[:, None], rms_vel_pred[:, None], rms_err[:, None]])\n",
    "points_lonlat = hv.Points(data_lonlat, kdims=['lon', 'lat'],\n",
    "                          vdims=['rms_vel', 'rms_vel_pred', 'rms_error'], label=\"RMS Velocity\")\n",
    "\n",
    "plt_opts = dict(width=600, height=350, colorbar=True, tools=['hover'])\n",
    "\n",
    "(rasterize(points_lonlat, x_sampling=0.12, y_sampling=0.12,\n",
    "          aggregator=datashader.mean('rms_vel')\n",
    "          ).redim.range(rms_vel=(0, 150)).opts(cmap=plt.cm.Blues, **plt_opts)\n",
    " +\n",
    " rasterize(points_lonlat, x_sampling=0.12, y_sampling=0.12,\n",
    "          aggregator=datashader.mean('rms_vel_pred')\n",
    "          ).redim.range(rms_vel_pred=(0, 150)).opts(cmap=plt.cm.Blues, title='RMS Velocity Predicted', **plt_opts)\n",
    " +\n",
    " rasterize(points_lonlat, x_sampling=0.12, y_sampling=0.12,\n",
    "          aggregator=datashader.mean('rms_error')\n",
    "          ).opts(cmap=plt.cm.Reds, title='RMS Error', **plt_opts)\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "The CNN model now kind of works, but it is not as good. I think this could be related to the fact that we are training on 32 x 32 squares but testing on the full global image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
